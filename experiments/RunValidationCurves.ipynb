{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Only run this once to set the directory!!! This could probably be done better but oh well\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output folder: output/mobile/training_hdNone_hc4_ne50_bs32_lr_0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "2022-05-05 12:09:40.199772: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.199921: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.201407: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.201445: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.201526: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.201885: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.203369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 12:09:40.203503: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:   30.4s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All-NaN slice encountered",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m~/School/gt/misc/SupervisedLearning/training_regression.py:220\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    203\u001B[0m     train_scores, valid_scores \u001B[38;5;241m=\u001B[39m validation_curve(\n\u001B[1;32m    204\u001B[0m         model,\n\u001B[1;32m    205\u001B[0m         x_train_dt,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    216\u001B[0m         pre_dispatch\u001B[38;5;241m=\u001B[39mPRE_DISPATCH,\n\u001B[1;32m    217\u001B[0m     )\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# Generate plot of the validation_curve\u001B[39;00m\n\u001B[0;32m--> 220\u001B[0m     \u001B[43mgenerate_validation_curve_plot\u001B[49m\u001B[43m(\u001B[49m\u001B[43marchitecture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mneural_network\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mparameter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidation_curve\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mparam_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_parameter_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mtrain_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43mvalid_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfull_path_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m grid_cv_search_flag:\n\u001B[1;32m    228\u001B[0m     clf \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    229\u001B[0m                        param_grid\u001B[38;5;241m=\u001B[39mgrid_cv_search_dict,\n\u001B[1;32m    230\u001B[0m                        cv\u001B[38;5;241m=\u001B[39mKFold(n_splits\u001B[38;5;241m=\u001B[39mCROSS_VALIDATION_NUM_SPLITS,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    237\u001B[0m                        pre_dispatch\u001B[38;5;241m=\u001B[39mPRE_DISPATCH,\n\u001B[1;32m    238\u001B[0m                        )\n",
      "File \u001B[0;32m~/School/gt/misc/SupervisedLearning/utils/plot.py:267\u001B[0m, in \u001B[0;36mgenerate_validation_curve_plot\u001B[0;34m(architecture, parameter, param_range, train_scores, valid_scores, output_file_path)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parameter \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_estimator__max_depth\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    264\u001B[0m     parameter \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    266\u001B[0m output_string \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaximum Validation Accuracy with \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m (Accuracy=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(parameter,\n\u001B[0;32m--> 267\u001B[0m                                                                                 param_range[\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnanargmax\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m                                                                                    \u001B[49m\u001B[43mvalid_scores_mean\u001B[49m\u001B[43m)\u001B[49m],\n\u001B[1;32m    269\u001B[0m                                                                                 np\u001B[38;5;241m.\u001B[39mnanmax(valid_scores_mean)\n\u001B[1;32m    270\u001B[0m                                                                                 )\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28mprint\u001B[39m(output_string)\n\u001B[1;32m    272\u001B[0m \u001B[38;5;66;03m# Write some simple information to a file to persist\u001B[39;00m\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mnanargmax\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/ml/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:614\u001B[0m, in \u001B[0;36mnanargmax\u001B[0;34m(a, axis, out, keepdims)\u001B[0m\n\u001B[1;32m    612\u001B[0m     mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mall(mask, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[1;32m    613\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39many(mask):\n\u001B[0;32m--> 614\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll-NaN slice encountered\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    615\u001B[0m res \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(a, axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, keepdims\u001B[38;5;241m=\u001B[39mkeepdims)\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "\u001B[0;31mValueError\u001B[0m: All-NaN slice encountered"
     ]
    }
   ],
   "source": [
    "# Run test for selected files\n",
    "%run training_regression.py \\\n",
    "     --dataset-path \\\n",
    "     datasets/mobile \\\n",
    "     --num-outputs \\\n",
    "       2 \\\n",
    "     --output-path \\\n",
    "     output \\\n",
    "     --hidden-layer-count \\\n",
    "     4 \\\n",
    "     --learning-rate \\\n",
    "     0.001 \\\n",
    "     --epochs \\\n",
    "     50 \\\n",
    "     --validation-curve \\\n",
    "     hidden_dim \\\n",
    "     --validation-parameter-range 32 64 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}